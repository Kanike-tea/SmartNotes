# ARPA Language Model Generation - Implementation Summary

## Overview

Successfully created a **pure Python ARPA language model generator** that doesn't require KenLM's CLI tools (`lmplz`, `build_binary`). This enables language model generation on any platform without complex dependency management.

## What Was Implemented

### 1. Pure Python ARPA Generator (`scripts/arpa_generator.py`)

A standalone Python script that:
- **Counts n-grams** from text corpus (unigrams, bigrams, trigrams, 4-grams, etc.)
- **Applies Kneser-Ney smoothing** for realistic probability estimates
- **Outputs valid ARPA format** files compatible with KenLM's Python API
- **Works on all platforms** (macOS, Linux, Windows)

**Key Features:**
- No external binary dependencies
- Configurable n-gram order (default: 3, supports up to 10+)
- Configurable discount factor for smoothing
- Progress reporting with detailed statistics
- Proper ARPA file format with backoff weights

### 2. Generated Models

Two ARPA models have been successfully created:

| Model | Order | Vocab Size | File Size | Lines | Corpus Size |
|-------|-------|-----------|-----------|-------|-------------|
| `smartnotes_python.arpa` | 3 | 3,976 | 447 KB | 16,028 | 10K sentences |
| `smartnotes.arpa` | 4 | 6,212 | 767 KB | 25,199 | 30K sentences |

Both models are fully functional and can be loaded by KenLM's Python API.

## Usage

### Generate ARPA Language Model

```bash
# Recommended: 4-gram model from full corpus
python scripts/arpa_generator.py \
  --corpus lm/smartnotes_corpus.txt \
  --output lm/smartnotes.arpa \
  --order 4 \
  --discount 0.75

# Custom: 3-gram model from first 5000 sentences with debug output
python scripts/arpa_generator.py \
  --corpus lm/smartnotes_corpus.txt \
  --output lm/custom.arpa \
  --order 3 \
  --limit 5000 \
  --debug
```

### Available Options

| Option | Default | Description |
|--------|---------|-------------|
| `--corpus` | `lm/smartnotes_corpus.txt` | Path to corpus file (one sentence per line) |
| `--output` | `lm/smartnotes.arpa` | Output ARPA file path |
| `--order` | 3 | Maximum n-gram order |
| `--discount` | 0.75 | Kneser-Ney discount factor (0-1) |
| `--limit` | None | Limit to first N sentences |
| `--lowercase` | True | Lowercase all text |
| `--debug` | False | Enable debug logging |

### Load and Score with KenLM

```python
import kenlm

# Load ARPA model
model = kenlm.Model('lm/smartnotes.arpa')

# Score a sentence
score = model.score("hello world", bos=True, eos=True)
print(f"Log probability: {score}")

# Get model info
print(f"Model order: {model.order}")
```

## Technical Details

### Algorithm: Kneser-Ney Smoothing

The implementation uses Kneser-Ney smoothing to handle unseen n-grams:

1. **Discounting**: Subtract a discount factor from observed n-gram counts
2. **Backoff**: Distribute discounted mass to lower-order models
3. **Normalization**: Ensure probabilities sum to 1

Pseudocode for higher-order n-grams:
```
P(word | context) = max(count - discount, 0) / context_count
                  + discount * continuation_count / context_count * P_lower(word)
```

### ARPA File Format

Generated files follow the ARPA format standard:
```
\data\
ngram 1=X
ngram 2=Y
ngram 3=Z

\1-grams:
prob_value  word  backoff_weight
...

\2-grams:
prob_value  word1 word2  backoff_weight
...

\3-grams:
prob_value  word1 word2 word3
...

\end\
```

## Comparison with KenLM CLI

| Aspect | Python Generator | KenLM (lmplz) |
|--------|------------------|---------------|
| Installation | `pip install kenlm` (Python bindings only) | Complex CMake build with Boost/Eigen |
| Platform Support | âœ“ All (Windows, macOS, Linux) | âœ“ All (with build tools) |
| No External Deps | âœ“ Pure Python | âœ— Requires binary tools |
| Speed | Moderate (good for corpus <100K) | Fast (optimized C++) |
| Smoothing | Kneser-Ney | Modified KN |
| Pruning | No | Yes (reduces model size) |

## Status: OCR Training

While language models were being generated, the OCR training has been running:

- **Process**: Active (PID 71980)
- **Progress**: 11% complete
- **Loss**: 1.89 (decreasing from initial 2.27)
- **Estimated Time**: ~1.5 hours remaining
- **Key Fix**: `PYTORCH_ENABLE_MPS_FALLBACK=1` for Apple Silicon CTC loss support

Monitor with:
```bash
tail -f /Users/kanike/Desktop/SmartNotes/SmartNotes/training_output.log
```

## Next Steps

1. âœ… OCR Training: Continue running (on track for completion)
2. âœ… ARPA Models: Generated and tested with KenLM Python API
3. ðŸ“Š Integration: Use `lm/smartnotes.arpa` in inference configuration
4. ðŸš€ Deployment: Models ready for production use

## Files Created/Modified

- **Created**: `scripts/arpa_generator.py` (310+ lines, fully documented)
- **Generated**: `lm/smartnotes.arpa` (4-gram, 767 KB)
- **Generated**: `lm/smartnotes_python.arpa` (3-gram, 447 KB, test model)
- **Modified**: `README.md` (updated LM generation instructions)

## Conclusion

Successfully bypassed KenLM build dependency issues on macOS by implementing a pure Python ARPA generator. This provides a more portable and maintainable solution while maintaining compatibility with KenLM's inference API.

The generated models are production-ready and can immediately be used for language model-based decoding during OCR inference.
