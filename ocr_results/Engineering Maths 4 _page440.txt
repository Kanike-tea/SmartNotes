STOCHASTIC PROCESS 431
ge

Let P be the t.p.m of the Markov chain and let p = (P;) = (Pye Pp, ++ Py, ) be the

probability distribution at some arbitrary time. Then p P,, p P?---p P" respectively
- are the probabilities of the system after one step, two steps,... 1 steps.

Let p°) = ere ee ---p®)] denote the initial probability distribution at the start

of the process and let pi” = A"), BS: pt] denote the n'® step probability
, distribution at the.end of n steps. Thus we have

yp) ss (9) p pi?) =< pp a po) 2, -- pl) es po) p™
Illustrations '

1. Let us consider the tp.m of the earlier illustrated Example-1
bob
pu'| 9 Ld) _|Pee Peo
b| 1/2'172 Pot Poo
We shall find P? and P°
2) 42)
Pp 01 l| 0 1 |«|Fewal Pe Pei

2) 2
v2.72 \| 72 v2)" [1/4 3/4 |") (2) 42)
3) (3)

z Li fill aaa “| ea ae" vty Hf |
* ~ ~} (3) (3)
1/2 1/2 || 1/4 3/4} | 3/8 5/8)" | (3) 96 >|

pe) = 1/2 means that the probability that the system changes from the state't to
b inexactly two steps is 1/2

Be ) = 3/8 meéans that the probability that the system changes from the state b to
* ¢ inexactly 3 steps is 3/8.

Next let us create an initial probability distribution for the start of the process. Let us
suppose that the person rolled adie’ and decided that he will go by bus if the number
appeared on the face is divisible by 3.

p(b) = 2/6 = 13 and p(t) = 2/3 |
Thatis p©) = (2/3, 1/3) is the initial probability distribution,

_ al =[5/12, 7/121

Now pl?) = p\) P? =[ 2/3, va] in aia